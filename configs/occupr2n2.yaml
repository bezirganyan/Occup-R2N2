method: occupr2n2
data:
  dataset: Shapes3D
  path: data/ShapeNet
  classes: null
  input_type: multi_img
  train_split: multi_train
  val_split: multi_val
  test_split: test
  dim: 3
  points_file: model_multi.npy
  points_iou_file: model_multi.npy
  points_subsample: 256
  points_unpackbits: true
  model_file: model.off
  watertight_file: model_watertight.off
  img_folder: render_128_stable
  img_size: 224
  img_with_camera: false
  img_augment: false
  n_views: 2
  pointcloud_file: pointcloud.npz
  pointcloud_chamfer_file: pointcloud.npz
  pointcloud_n: 256
  pointcloud_target_n: 1024
  pointcloud_noise: 0.05
  voxels_file: 'model_multi.binvox'
  with_transforms: false
  binary_occ: false
model:
  decoder: cbatchnorm
  encoder: 3dconvgru
  encoder_latent: null
  decoder_kwargs: {}
  encoder_kwargs: {}
  encoder_latent_kwargs: {}
  instance_loss: True
  multi_gpu: false
  c_dim: 128
  z_dim: 0
  use_camera: false
  dmc_weight_prior: 10.
  decoder_local: batchnorm_localfeature
  decoder_local_kwargs: {}
  local_feature_dim: 64
  logits2_ratio: 1.
  logits1_ratio: 1.
  local_feature_mask: false
  n_classes: 2
training:
  out_dir:  out/final
  batch_size: 4
  print_every: 10
  visualize_every: 2000
  checkpoint_every: 1000
  validate_every: 100
  backup_every: 100000
  eval_sample: false
  model_selection_metric: loss
  model_selection_mode: minimize
  loss_type: cross_entropy
  loss_tolerance_episolon: {}
  sign_lambda: {}
test:
  threshold: 0.5
  eval_mesh: true
  eval_pointcloud: true
  model_file: model_best.pt
generation:
  batch_size: 100000
  refinement_step: 0
  vis_n_outputs: 30
  generate_mesh: true
  generate_pointcloud: true
  generation_dir: generation
  use_sampling: false
  resolution_0: 32
  upsampling_steps: 2
  simplify_nfaces: null
  copy_groundtruth: false
  copy_input: true
  latent_number: 4
  latent_H: 8
  latent_W: 8
  latent_ny: 2
  latent_nx: 2
  latent_repeat: true
preprocessor:
  type: null
  config: ""
  model_file: null
